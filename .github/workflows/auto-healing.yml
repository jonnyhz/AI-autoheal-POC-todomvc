name: AI Auto-Healing Pipeline

on:
  workflow_run:
    workflows: ["Cypress E2E Tests with Auto-Healing"]
    types: [completed]
    branches: [master, main]

jobs:
  auto-healing:
    runs-on: ubuntu-latest
    if: ${{ github.event.workflow_run.conclusion == 'failure' }}
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        ref: master
        
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'
        
    - name: Download Cypress screenshots (if available)
      uses: actions/download-artifact@v4
      with:
        name: cypress-screenshots
        path: cypress/screenshots
        github-token: ${{ secrets.GITHUB_TOKEN }}
        repository: ${{ github.repository }}
        run-id: ${{ github.event.workflow_run.id }}
        
    - name: Download DOM content (if available)
      uses: actions/download-artifact@v4
      with:
        name: cypress-dom-content
        path: cypress/failures
        github-token: ${{ secrets.GITHUB_TOKEN }}
        repository: ${{ github.repository }}
        run-id: ${{ github.event.workflow_run.id }}
        
    - name: Analyze test failures
      run: |
        echo "🔍 Analyzing test failures for auto-healing..."
        echo "Test failure detected in workflow: ${{ github.event.workflow_run.name }}"
        echo "Workflow run ID: ${{ github.event.workflow_run.id }}"
        echo "Failure URL: ${{ github.event.workflow_run.html_url }}"
        
        # Check if artifacts were downloaded
        if [ -d "cypress/screenshots" ] && [ "$(ls -A cypress/screenshots 2>/dev/null)" ]; then
          echo "✅ Screenshots found and downloaded"
          echo "📸 Available screenshots:"
          ls -la cypress/screenshots/
        else
          echo "⚠️ No screenshots available for analysis"
        fi
        
        # Check if DOM content was downloaded
        if [ -d "cypress/failures" ] && [ "$(ls -A cypress/failures 2>/dev/null)" ]; then
          echo "✅ DOM content found and downloaded"
          echo "🌐 Available DOM files:"
          ls -la cypress/failures/
        else
          echo "⚠️ No DOM content available for analysis"
        fi
        
        # Note: Videos are disabled in cypress.json (video: false)
        echo "ℹ️ Videos are disabled in Cypress configuration"
        
    - name: AI Analysis with 
      run: |
       echo "🤖 Sending test context to OpenAI for analysis..."
       echo "Preparing test context..."
       # Get test file content
       if [ -f "tests/e2e/new-todo.spec.js" ]; then
         echo "📄 Test file found"
         TEST_CONTENT=$(cat tests/e2e/new-todo.spec.js)
       else
         echo "⚠️ Test file not found"
         TEST_CONTENT="Test file not available"
       fi
       # Get DOM content if available
       if [ -d "cypress/failures" ] && [ "$(ls -A cypress/failures 2>/dev/null)" ]; then
         DOM_FILE=$(ls cypress/failures/*.html | head -1)
         if [ -f "$DOM_FILE" ]; then
           echo "🌐 DOM content found: $DOM_FILE"
           DOM_CONTENT=$(head -c 2000 "$DOM_FILE")
         else
           DOM_CONTENT="DOM content not available"
         fi
       else
         DOM_CONTENT="DOM content not available"
       fi
       # Create OpenAI API payload with jq
       jq -n \
         --arg test_content "$TEST_CONTENT" \
         --arg dom_content "$DOM_CONTENT" \
         --arg repo "${{ github.repository }}" \
         --arg workflow "${{ github.event.workflow_run.name }}" \
         --arg url "${{ github.event.workflow_run.html_url }}" \
         '{
           model: "gpt-4",
           messages: [
             {
               role: "system",
               content: "You are an expert test automation engineer specializing in fixing Cypress test failures. Analyze test failures and provide specific selector/locator fixes."
             },
             {
               role: "user",
               content: (
                 "Analyze the following test failure and provide specific selector/locator fixes.\n\n" +
                 "**INSTRUCTIONS:**\n" +
                 "1. Compare the test expectations with the actual DOM content\n" +
                 "2. Identify why selectors are failing (element not found, text mismatch, etc.)\n" +
                 "3. Provide the exact code changes needed to fix the test\n" +
                 "4. Focus on selector/locator fixes only\n" +
                 "5. Respond in JSON format with 'analysis' and 'fix' fields\n\n" +
                 "**TEST FILE:**\n```javascript\n" + $test_content + "\n```\n\n" +
                 "**ACTUAL DOM CONTENT:**\n```html\n" + $dom_content + "\n```\n\n" +
                 "**WORKFLOW INFO:**\n" +
                 "- Repository: " + $repo + "\n" +
                 "- Workflow: " + $workflow + "\n" +
                 "- Failure URL: " + $url + "\n\n" +
                 "Provide your analysis and fix in JSON format."
               )
             }
           ],
           max_tokens: 1000,
           temperature: 0.1
         }' > openai_payload.json
         
       echo "Request payload: "
       cat openai_payload.json
         
       echo "✅ OpenAI API payload prepared"
       # Send to OpenAI API
       if [ -n "${{ secrets.OPENAI_API_KEY }}" ]; then
         echo "🔄 Sending request to OpenAI API..."
         OPENAI_RESPONSE=$(curl -s -X POST https://api.openai.com/v1/chat/completions \
           -H "Content-Type: application/json" \
           -H "Authorization: Bearer ${{ secrets.OPENAI_API_KEY }}" \
           -d @openai_payload.json)
         echo "✅ OpenAI API response received"
         echo "$OPENAI_RESPONSE" > openai_response.json
         if echo "$OPENAI_RESPONSE" | jq -e '.choices[0].message.content' > /dev/null 2>&1; then
           OPENAI_ANALYSIS=$(echo "$OPENAI_RESPONSE" | jq -r '.choices[0].message.content')
           echo "🤖 OpenAI Analysis:"
           echo "$OPENAI_ANALYSIS"
           echo "$OPENAI_ANALYSIS" > openai_analysis.txt
           echo "✅ OpenAI analysis saved for fix application"
         else
           echo "❌ Error parsing OpenAI response"
           echo "$OPENAI_RESPONSE"
         fi
       else
         echo "⚠️ OPENAI_API_KEY not found in secrets"
         echo "🔄 Skipping OpenAI API call - add OPENAI_API_KEY to repository secrets"
         cat > openai_analysis.txt <<EOF
         {
         "analysis": "Mock analysis: Test is looking for h1 with text 'todos' but DOM contains h1 with text 'todo's'",
         "fix": "Update the test selector from cy.contains('h1', 'todos') to cy.contains('h1', \"todo's\")"
         }
         EOF
         echo "📄 Mock analysis created for testing purposes"
       fi
       echo "📊 Context summary:"
       echo "- Test content: $(echo "$TEST_CONTENT" | wc -l) lines"
       echo "- DOM content: $(echo "$DOM_CONTENT" | wc -c) characters"
       echo "- Has screenshots: $([ -d "cypress/screenshots" ] && [ "$(ls -A cypress/screenshots 2>/dev/null)" ] && echo "Yes" || echo "No")"
       echo "- Has DOM content: $([ -d "cypress/failures" ] && [ "$(ls -A cypress/failures 2>/dev/null)" ] && echo "Yes" || echo "No")"
        
    - name: Generate AI-powered fixes
      run: |
        echo "🤖 Generating AI-powered fixes based on OpenAI analysis..."
        
        if [ -f "openai_analysis.txt" ]; then
          echo "📄 OpenAI analysis found, processing recommendations..."
          
          OPENAI_ANALYSIS=$(cat openai_analysis.txt)
          echo "🔍 OpenAI's Analysis:"
          echo "$OPENAI_ANALYSIS"
          
          # Try to parse JSON response
          if echo "$OPENAI_ANALYSIS" | jq -e '.' > /dev/null 2>&1; then
            ANALYSIS=$(echo "$OPENAI_ANALYSIS" | jq -r '.analysis // empty')
            FIX=$(echo "$OPENAI_ANALYSIS" | jq -r '.fix // empty')
            
            echo "📊 Parsed Analysis: $ANALYSIS"
            echo "🔧 Recommended Fix: $FIX"
            
            # Save fix for application step
            echo "$FIX" > recommended_fix.txt
            echo "✅ Fix recommendation saved"
            
          else
            echo "📝 Non-JSON response, extracting fix information..."
            # If OpenAI responds in plain text, save it for manual review
            echo "$OPENAI_ANALYSIS" > recommended_fix.txt
            echo "✅ Analysis saved for review"
          fi
          
        else
          echo "⚠️ No OpenAI analysis found, using fallback approach"
          echo "🔄 Fallback: Basic selector update based on common patterns"
          
          # Create a basic fix suggestion
          cat > recommended_fix.txt << EOF
        Fallback fix: Check for common issues:
        1. Text content mismatch (todos vs todo's)
        2. Element not found
        3. Timing issues
        4. Selector changes
        EOF
        fi
        
        echo "✅ AI-powered fix generation completed"
        
    - name: Create auto-healing branch
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git checkout -b auto-healing/fix-${{ github.run_number }}-${{ github.sha }}
        
    - name: Apply AI-generated fixes
      run: |
        echo "🔧 Applying AI-generated fixes..."
        
        if [ -f "recommended_fix.txt" ]; then
          echo "📄 Fix recommendations found"
          
          RECOMMENDED_FIX=$(cat recommended_fix.txt)
          echo "🔍 Recommended fix: $RECOMMENDED_FIX"
          
          # For now, just document the recommended fixes as comments
          echo "📝 Creating fix documentation..."
          
          # Create a summary of recommended changes
          echo "📊 Summary of recommended fixes:" > fix_summary.txt
          echo "- Recommendation: $RECOMMENDED_FIX" >> fix_summary.txt
          echo "- Files to modify: tests/e2e/new-todo.spec.js" >> fix_summary.txt
          echo "- Change type: Selector/locator update" >> fix_summary.txt
          echo "- Status: Documented for manual review" >> fix_summary.txt
          
          echo "✅ Fix recommendations documented"
          echo "📋 Manual review required to apply changes"
          
        else
          echo "⚠️ No fix recommendations found"
          echo "📝 Creating placeholder fix summary"
          
          cat > fix_summary.txt << EOF
        No specific fixes recommended.
        Manual review of test failure required.
        Check Claude analysis for detailed recommendations.
        EOF
        fi
        
        echo "✅ Fix documentation completed"
        
    - name: Push auto-healing branch
      run: |
        git push origin auto-healing/fix-${{ github.run_number }}-${{ github.sha }}
        
    - name: Create Pull Request
      uses: peter-evans/create-pull-request@v5
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        title: "🤖 Auto-healing: Fix test failures"
        body: |
          ## AI Auto-Healing Fix
          
          This PR contains automated fixes for failing tests detected by the auto-healing pipeline.
          
          **Changes made:**
          - [ ] Updated selectors
          - [ ] Fixed timing issues  
          - [ ] Updated test expectations
          - [ ] Added retry mechanisms
          
          **Test Results:**
          - Original failure: ${{ github.event.workflow_run.html_url }}
          - Auto-healing run: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}
          
          **Next Steps:**
          1. Review the changes
          2. Run tests locally
          3. Merge if tests pass
        branch: auto-healing/fix-${{ github.run_number }}-${{ github.sha }}
        base: master
        delete-branch: true 
